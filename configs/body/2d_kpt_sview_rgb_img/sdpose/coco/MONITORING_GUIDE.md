# í•™ìŠµ ëª¨ë‹ˆí„°ë§ ê°€ì´ë“œ

## ğŸ¯ ì£¼ìš” ë³€ê²½ì‚¬í•­

### 1. **ì›ë³¸ SDPoseë¡œ ë³µì›**
- âŒ ì œê±°: Token/Heatmap Clamping (í•™ìŠµ ë°©í•´)
- âŒ ì œê±°: MaskedTokenDistilLoss (self-distillationê³¼ ë¶€ì í•©)
- âœ… ë³µì›: ì›ë³¸ TokenDistilLoss (loss_weight=5e-6)

### 2. **ëª¨ë‹ˆí„°ë§ ê°•í™”**
- âœ… Evaluation interval: 10 â†’ 5 epoch (ë” ìì£¼ ì²´í¬)
- âœ… TrainingMonitorHook: Loss spike, ì„±ëŠ¥ í•˜ë½ ìë™ ê°ì§€
- âœ… DetailedLossLogHook: ëª¨ë“  loss í•­ëª© ìƒì„¸ ë¡œê¹…

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. **í•™ìŠµ ì „ ì²´í¬ (ê¶Œì¥)**
```bash
# ëª‡ iterationë§Œ ì‹¤í–‰í•˜ì—¬ ì •ìƒ ì‘ë™ í™•ì¸
python tools/quick_check.py configs/body/2d_kpt_sview_rgb_img/sdpose/coco/sdpose_s_v1_stemnet_coco_256x192.py --iterations 10
```

**í™•ì¸ì‚¬í•­:**
- âœ… Forward pass ì •ìƒ ì‘ë™
- âœ… Loss ê°’ì´ NaN/Infê°€ ì•„ë‹˜
- âœ… ëª¨ë“  loss í•­ëª©ì´ ê³„ì‚°ë¨

### 2. **ì •ì‹ í•™ìŠµ ì‹œì‘**
```bash
# ë‹¨ì¼ GPU
python tools/train.py configs/body/2d_kpt_sview_rgb_img/sdpose/coco/sdpose_s_v1_stemnet_coco_256x192.py

# ë©€í‹° GPU (ì˜ˆ: 4 GPUs)
bash tools/dist_train.sh configs/body/2d_kpt_sview_rgb_img/sdpose/coco/sdpose_s_v1_stemnet_coco_256x192.py 4
```

---

## ğŸ“Š ë¡œê·¸ ëª¨ë‹ˆí„°ë§

### **ìë™ ê°ì§€ ê¸°ëŠ¥**

#### 1. **Loss Spike ê°ì§€**
```
âš ï¸  WARNING: Loss spike detected!
   Current: 5.2341
   Recent avg: 2.1234
   Ratio: 2.47x
```
**ì˜ë¯¸:** Lossê°€ ê°‘ìê¸° 2ë°° ì´ìƒ ì¦ê°€
**ì¡°ì¹˜:** 
- Learning rateê°€ ë„ˆë¬´ ë†’ì€ì§€ í™•ì¸
- Gradient clipping í™•ì¸ (í˜„ì¬: max_norm=5.0)
- ë°ì´í„° ì´ìƒ í™•ì¸

#### 2. **ì„±ëŠ¥ í•˜ë½ ê°ì§€**
```
âš ï¸  WARNING: Performance drop detected!
   Current AP: 0.650
   Best AP: 0.720
   Drop: 0.070
```
**ì˜ë¯¸:** APê°€ ì´ì „ ìµœê³ ì¹˜ë³´ë‹¤ 0.05 ì´ìƒ í•˜ë½
**ì¡°ì¹˜:**
- Overfitting ê°€ëŠ¥ì„±
- Learning rate schedule í™•ì¸
- ì´ì „ checkpointë¡œ ë³µì› ê³ ë ¤

#### 3. **ìƒì„¸ Loss ë¡œê¹…**
```
Iter [50] loss: 2.345678, heatmap_loss: 2.100000, vis_dist_loss: 0.000123, kpt_dist_loss: 0.000234
Iter [100] loss: 2.123456, heatmap_loss: 1.950000, vis_dist_loss: 0.000087, kpt_dist_loss: 0.000165
```
**í™•ì¸ì‚¬í•­:**
- `heatmap_loss`: ë©”ì¸ loss, ì ì§„ì ìœ¼ë¡œ ê°ì†Œí•´ì•¼ í•¨
- `vis_dist_loss`: ~1e-4 ìˆ˜ì¤€ (5e-6 weight)
- `kpt_dist_loss`: ~1e-4 ìˆ˜ì¤€ (5e-6 weight)

---

## ğŸ“ˆ ì •ìƒ í•™ìŠµ íŒ¨í„´

### **Epochë³„ ì˜ˆìƒ ì„±ëŠ¥**

| Epoch | Loss | AP | ë¹„ê³  |
|-------|------|-----|------|
| 1-10 | 3.0 â†’ 1.5 | 0.1 â†’ 0.3 | ì´ˆê¸° í•™ìŠµ |
| 10-50 | 1.5 â†’ 0.8 | 0.3 â†’ 0.55 | ë¹ ë¥¸ ê°œì„  |
| 50-150 | 0.8 â†’ 0.5 | 0.55 â†’ 0.68 | ì•ˆì •ì  ê°œì„  |
| 150-250 | 0.5 â†’ 0.4 | 0.68 â†’ 0.72 | ëŠë¦° ê°œì„  |
| 250-300 | 0.4 â†’ 0.38 | 0.72 â†’ 0.73 | ìˆ˜ë ´ |

### **ì˜ˆìƒ ìµœì¢… ì„±ëŠ¥**
- **AP**: ~0.730 (COCO validation)
- **Params**: ~9M
- **GFLOPs**: ~4.5

---

## ğŸ” ë¬¸ì œ ì§„ë‹¨

### **Case 1: Lossê°€ ê°ì†Œí•˜ì§€ ì•ŠìŒ**
```
Epoch 10: Loss = 3.2
Epoch 20: Loss = 3.1
Epoch 30: Loss = 3.0
```
**ê°€ëŠ¥í•œ ì›ì¸:**
1. Learning rateê°€ ë„ˆë¬´ ì‘ìŒ â†’ configì—ì„œ ì¦ê°€ ì‹œë„ (1e-3 â†’ 3e-3)
2. Batch sizeê°€ ë„ˆë¬´ ì‘ìŒ â†’ ìµœì†Œ 32 ì´ìƒ ê¶Œì¥
3. ë°ì´í„° augmentationì´ ë„ˆë¬´ ê°•í•¨ â†’ ì¤„ì—¬ë³´ê¸°

### **Case 2: APê°€ 0.0000**
```
Epoch 100: AP = 0.0000
```
**ê°€ëŠ¥í•œ ì›ì¸:**
1. âŒ Heatmapì´ ì œëŒ€ë¡œ ìƒì„±ë˜ì§€ ì•ŠìŒ
2. âŒ ëª¨ë¸ ì¶œë ¥ì´ ì´ìƒí•¨ (NaN, Inf, ê·¹ë‹¨ê°’)

**ì¦‰ì‹œ ì¡°ì¹˜:**
```bash
# Quick check ì‹¤í–‰
python tools/quick_check.py configs/body/2d_kpt_sview_rgb_img/sdpose/coco/sdpose_s_v1_stemnet_coco_256x192.py

# ë¡œê·¸ì—ì„œ NaN/Inf í™•ì¸
grep -i "nan\|inf" work_dirs/*/latest.log
```

### **Case 3: Lossê°€ ê¸‰ì¦ í›„ ë°œì‚°**
```
Epoch 45: Loss = 0.8
Epoch 46: Loss = 2.5
Epoch 47: Loss = NaN
```
**ê°€ëŠ¥í•œ ì›ì¸:**
1. Gradient explosion â†’ Gradient clipping ê°•í™” (5.0 â†’ 3.0)
2. Learning rateê°€ ë„ˆë¬´ ë†’ìŒ â†’ ê°ì†Œ ë˜ëŠ” warmup ì¶”ê°€
3. Batch size ë³€ê²½ ì‹œ ë°œìƒ â†’ Learning rateë„ í•¨ê»˜ ì¡°ì •

---

## ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬

### **í˜„ì¬ ì„¤ì •**
```python
checkpoint_config = dict(
    interval=10,           # 10 epochë§ˆë‹¤ ì €ì¥
    max_keep_ckpts=3,     # ìµœê·¼ 3ê°œë§Œ ìœ ì§€
    save_last=True,       # latest.pthëŠ” í•­ìƒ ìœ ì§€
)
```

### **ë³µì› ë°©ë²•**
```bash
# íŠ¹ì • epochë¶€í„° ì¬ì‹œì‘
python tools/train.py \
    configs/body/2d_kpt_sview_rgb_img/sdpose/coco/sdpose_s_v1_stemnet_coco_256x192.py \
    --resume-from work_dirs/sdpose_s_v1_1024_baseline/epoch_100.pth

# Best modelë¡œ ì¬ì‹œì‘
python tools/train.py \
    configs/body/2d_kpt_sview_rgb_img/sdpose/coco/sdpose_s_v1_stemnet_coco_256x192.py \
    --resume-from work_dirs/sdpose_s_v1_1024_baseline/best_AP_epoch_150.pth
```

---

## ğŸ“ í†µê³„ íŒŒì¼

í•™ìŠµ ì™„ë£Œ í›„ ìë™ ìƒì„±ë˜ëŠ” íŒŒì¼:
```
work_dirs/sdpose_s_v1_1024_baseline/
â”œâ”€â”€ training_stats.txt       # ì „ì²´ í•™ìŠµ í†µê³„
â”œâ”€â”€ *.log                     # í•™ìŠµ ë¡œê·¸
â””â”€â”€ *.log.json               # JSON í˜•ì‹ ë¡œê·¸
```

### **training_stats.txt ì˜ˆì‹œ**
```
Training Statistics
================================================================================

Loss Statistics:
  - Mean: 0.8543
  - Std: 0.2341
  - Min: 0.3821
  - Max: 3.2145
  - Final: 0.3912

Best AP: 0.7234
```

---

## ğŸ“ íŒ

### **1. í•™ìŠµ ì´ˆë°˜ (Epoch 1-50)**
- Lossê°€ ë¹ ë¥´ê²Œ ê°ì†Œí•´ì•¼ í•¨
- APê°€ 0.5 ì´ìƒ ë„ë‹¬í•´ì•¼ í•¨
- ì´ ì‹œê¸°ì— ë¬¸ì œê°€ ìˆìœ¼ë©´ config ì ê²€ í•„ìš”

### **2. í•™ìŠµ ì¤‘ë°˜ (Epoch 50-150)**
- ì•ˆì •ì ì¸ ê°œì„  ê¸°ëŒ€
- Loss spikeê°€ ë°œìƒí•˜ë©´ learning rate schedule í™•ì¸
- AP ì •ì²´ ì‹œ augmentation ê°•í™” ê³ ë ¤

### **3. í•™ìŠµ í›„ë°˜ (Epoch 150-300)**
- ëŠë¦¬ì§€ë§Œ ê¾¸ì¤€í•œ ê°œì„ 
- Overfitting ì£¼ì˜ (validation AP í•˜ë½ ì‹œ)
- Early stopping ê³ ë ¤ ê°€ëŠ¥

### **4. ì‹¤í—˜ ê´€ë¦¬**
```python
# Configì—ì„œ ì‹¤í—˜ ì´ë¦„ ë³€ê²½
date = '1027'
exp_description = 'original_sdpose'  # ì‹¤í—˜ ë‚´ìš©
exp_name = f'sdpose_s_v1_{date}_{exp_description}'
# â†’ work_dirs/sdpose_s_v1_1027_original_sdpose/
```

---

## ğŸ†˜ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### **ë¬¸ì œ: CUDA out of memory**
```python
# Config ìˆ˜ì •
data = dict(
    samples_per_gpu=64,  # â†’ 32ë¡œ ì¤„ì´ê¸°
    workers_per_gpu=2,
)
```

### **ë¬¸ì œ: í•™ìŠµì´ ë„ˆë¬´ ëŠë¦¼**
```python
# ë°ì´í„° ë¡œë” ì›Œì»¤ ì¦ê°€
data = dict(
    samples_per_gpu=64,
    workers_per_gpu=2,  # â†’ 4 ë˜ëŠ” 8ë¡œ ì¦ê°€
)
```

### **ë¬¸ì œ: Hook import ì—ëŸ¬**
```bash
# Hook íŒŒì¼ ìœ„ì¹˜ í™•ì¸
ls distilpose/models/detectors/training_monitor_hook.py

# mmcv ë²„ì „ í™•ì¸
python -c "import mmcv; print(mmcv.__version__)"
# ìµœì†Œ: 1.3.0 í•„ìš”
```

---

## ğŸ“ ë„ì›€ì´ í•„ìš”í•˜ë©´

1. **ë¡œê·¸ í™•ì¸**: `work_dirs/*/latest.log`
2. **Quick check ì‹¤í–‰**: ëª¨ë¸ì´ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
3. **í†µê³„ í™•ì¸**: `training_stats.txt`ì—ì„œ ì´ìƒ íŒ¨í„´ ì°¾ê¸°
4. **ì´ì „ checkpointë¡œ ë³µì›**: ë¬¸ì œê°€ ìƒê¸´ ì‹œì  ì´ì „ìœ¼ë¡œ

